{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TejasJoshi2005/Modal-Analysis-of-Fluid-Flows/blob/main/Turbulent_flow_past_cylinders_for_verying_Re_number.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPq2xYCRKgff"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# Step 0: Import Necessary Libraries\n",
        "# ==============================================================================\n",
        "# We need these libraries to work with our data:\n",
        "# - pandas: For loading and handling our data files.\n",
        "# - numpy: For numerical operations, especially the math behind POD and DMD.\n",
        "# - matplotlib.pyplot: For creating plots to visualize our results.\n",
        "# - glob: To automatically find all of our data files in the directory.\n",
        "# - os: To help with file path and name manipulation.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import svd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 1: Define the Main Analysis Function\n",
        "# ==============================================================================\n",
        "# We will create a primary function to handle the entire analysis for a single file.\n",
        "# This makes our code clean and allows us to easily loop through all your data files later.\n",
        "\n",
        "def process_and_analyze_flow_data(file_path, show_plots=True):\n",
        "    \"\"\"\n",
        "    This function takes the path to a velocity data file and performs a full\n",
        "    POD and DMD analysis, printing and plotting the results.\n",
        "    \"\"\"\n",
        "    file_name = os.path.basename(file_path)\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üöÄ Starting Analysis for: {file_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # --- Part A: Load and Prepare the Data ---\n",
        "    print(\"\\n[Part A] Loading and preparing the data...\")\n",
        "    try:\n",
        "        # Load the text file into a pandas DataFrame.\n",
        "        # The data is space-separated, has no header, and we'll name the columns 'time' and 'velocity'.\n",
        "        data = pd.read_csv(file_path, sep='\\s+', header=None, names=['time', 'velocity'])\n",
        "        signal = data['velocity'].values  # This is our main 1D data signal (a numpy array)\n",
        "        time = data['time'].values\n",
        "        dt = time[1] - time[0]  # Calculate the time step between measurements\n",
        "        print(f\"Data loaded successfully. Found {len(signal)} data points.\")\n",
        "        print(f\"Time step (dt) is: {dt:.4f} seconds (Sampling Frequency: {1/dt:.0f} Hz)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading file {file_name}: {e}\")\n",
        "        return None # Stop analysis for this file if it can't be loaded\n",
        "\n",
        "    # --- Part B: Create the Snapshot Matrix ---\n",
        "    # Both POD and DMD require the 1D time series data to be converted into a 2D matrix.\n",
        "    # We do this by creating a \"sliding window\" over the signal.\n",
        "    print(\"\\n[Part B] Creating the snapshot matrix...\")\n",
        "    window_size = 1000  # How many data points in each snapshot. This is a key parameter.\n",
        "    n_snapshots = len(signal) - window_size + 1\n",
        "\n",
        "    # Create the matrix 'X' where each column is a snapshot of the signal.\n",
        "    X = np.array([signal[i:i + window_size] for i in range(n_snapshots)]).T\n",
        "    print(f\"Snapshot matrix 'X' created with shape: {X.shape} (window_size x n_snapshots)\")\n",
        "\n",
        "\n",
        "    # --- Part C: Proper Orthogonal Decomposition (POD) ---\n",
        "    # POD finds the dominant spatial patterns (modes) in the data.\n",
        "    print(\"\\n[Part C] Performing Proper Orthogonal Decomposition (POD)...\")\n",
        "\n",
        "    # The core of POD is the Singular Value Decomposition (SVD).\n",
        "    # U: Contains the POD modes (the \"spatial shapes\").\n",
        "    # S: Contains the singular values (the \"energy\" of each mode).\n",
        "    # Vt: Contains the temporal evolution of each mode.\n",
        "    U, S, Vt = svd(X, full_matrices=False)\n",
        "\n",
        "    print(\"SVD computed for POD.\")\n",
        "\n",
        "    if show_plots:\n",
        "        # Plot the energy of each mode. You'll typically see that the first few modes\n",
        "        # contain almost all of the energy of the system.\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.semilogy(S / np.sum(S), 'o-', color='blue')\n",
        "        plt.title(f'POD Energy Spectrum for {file_name}')\n",
        "        plt.xlabel('Mode Number')\n",
        "        plt.ylabel('Normalized Singular Value (Energy)')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    # --- Part D: Dynamic Mode Decomposition (DMD) ---\n",
        "    # DMD finds the dominant dynamic behaviors (modes that oscillate and grow/decay at a certain rate).\n",
        "    print(\"\\n[Part D] Performing Dynamic Mode Decomposition (DMD)...\")\n",
        "\n",
        "    # DMD works by finding a linear mapping from the state at one time to the next.\n",
        "    # So, we create two matrices: X1 (current states) and X2 (next states).\n",
        "    X1 = X[:, :-1]\n",
        "    X2 = X[:, 1:]\n",
        "\n",
        "    # Step 1 of DMD: Decompose the first matrix X1 using SVD.\n",
        "    U_dmd, S_dmd, Vt_dmd = svd(X1, full_matrices=False)\n",
        "\n",
        "    # Step 2: Calculate the DMD operator 'A' that approximates X2 ‚âà A @ X1.\n",
        "    # We compute a low-rank version called A_tilde.\n",
        "    A_tilde = U_dmd.T @ X2 @ Vt_dmd.T @ np.diag(1./S_dmd)\n",
        "\n",
        "    # Step 3: Find the eigenvalues and eigenvectors of this operator.\n",
        "    # The eigenvalues tell us about the frequency and stability of the modes.\n",
        "    eigenvalues, eigenvectors = np.linalg.eig(A_tilde)\n",
        "    print(\"DMD operator computed and eigenvalues found.\")\n",
        "\n",
        "    # Step 4: Reconstruct the DMD modes.\n",
        "    dmd_modes = X2 @ Vt_dmd.T @ np.diag(1./S_dmd) @ eigenvectors\n",
        "\n",
        "    # Calculate the continuous-time eigenvalues (frequencies and growth rates).\n",
        "    omegas = np.log(eigenvalues) / dt\n",
        "    frequencies = np.imag(omegas) / (2 * np.pi)  # The oscillation frequencies in Hz.\n",
        "    growth_rates = np.real(omegas)               # The growth/decay rates.\n",
        "\n",
        "    # Find the dominant frequency (likely the vortex shedding frequency).\n",
        "    # We ignore very low frequencies and look for the mode with the highest energy.\n",
        "    valid_indices = np.where(np.abs(frequencies) > 1)[0]\n",
        "    dominant_frequency = 0\n",
        "    if len(valid_indices) > 0:\n",
        "        mode_amplitudes = np.linalg.norm(dmd_modes, axis=0)\n",
        "        dominant_mode_idx = valid_indices[np.argmax(mode_amplitudes[valid_indices])]\n",
        "        dominant_frequency = frequencies[dominant_mode_idx]\n",
        "        print(f\"‚úÖ Dominant Frequency Found: {dominant_frequency:.2f} Hz\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Could not identify a clear dominant frequency.\")\n",
        "\n",
        "\n",
        "    if show_plots:\n",
        "        # Plot the DMD eigenvalues on the complex plane.\n",
        "        # This is the classic DMD plot. Modes on the red circle are stable.\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.scatter(np.real(eigenvalues), np.imag(eigenvalues), c=np.abs(frequencies), alpha=0.7)\n",
        "        unit_circle = plt.Circle((0,0), 1, color='r', fill=False, linestyle='--')\n",
        "        plt.gca().add_artist(unit_circle)\n",
        "        plt.title(f'DMD Eigenvalues for {file_name}')\n",
        "        plt.xlabel('Real Part')\n",
        "        plt.ylabel('Imaginary Part')\n",
        "        plt.axis('equal')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    return file_name, dominant_frequency\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 2: Run the Analysis for All Your Files\n",
        "# ==============================================================================\n",
        "\n",
        "# Use glob to automatically find all files that match the pattern \"Velocity_*.txt\".\n",
        "# This is much better than typing each file name manually.\n",
        "all_files = glob.glob('Velocity_*.txt')\n",
        "all_files.sort()\n",
        "\n",
        "# A dictionary to store the final results for our summary table.\n",
        "results_summary = {}\n",
        "\n",
        "if not all_files:\n",
        "    print(\"‚ùå No data files found! Make sure your 'Velocity_*.txt' files are in the correct directory.\")\n",
        "else:\n",
        "    print(f\"\\nFound {len(all_files)} files. Starting batch analysis...\")\n",
        "    # Loop through each file path and run our analysis function.\n",
        "    for file_path in all_files:\n",
        "        # Set show_plots=False if you don't want to see the plots for every single file.\n",
        "        file_name, freq = process_and_analyze_flow_data(file_path, show_plots=True)\n",
        "        if freq is not None:\n",
        "            results_summary[file_name] = freq\n",
        "\n",
        "# ==============================================================================\n",
        "# Step 3: Display the Final Summary\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\\n--- üìä FINAL SUMMARY ---\")\n",
        "if results_summary:\n",
        "    print(f\"{'File Name':<30} | {'Dominant Frequency (Hz)':<30}\")\n",
        "    print(\"-\" * 62)\n",
        "    for name, freq in results_summary.items():\n",
        "        print(f\"{name:<30} | {freq:.2f}\")\n",
        "    print(\"-\" * 62)\n",
        "else:\n",
        "    print(\"No results to display. Please check for errors during analysis.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.linalg import svd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def analyze_dmd_results(file_path):\n",
        "    \"\"\"\n",
        "    Analyzes a velocity data file using DMD and returns the dominant frequency\n",
        "    and its corresponding modal amplitude.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- 1. Load Data ---\n",
        "        data = pd.read_csv(file_path, sep='\\s+', header=None, names=['time', 'velocity'])\n",
        "        signal = data['velocity'].values\n",
        "        dt = data['time'].iloc[1] - data['time'].iloc[0]\n",
        "\n",
        "        # --- 2. Create Snapshot Matrix ---\n",
        "        window_size = 1000\n",
        "        X = np.array([signal[i:i + window_size] for i in range(len(signal) - window_size + 1)]).T\n",
        "\n",
        "        # --- 3. Perform DMD ---\n",
        "        X1, X2 = X[:, :-1], X[:, 1:]\n",
        "        U, S, Vt = svd(X1, full_matrices=False)\n",
        "        A_tilde = U.T @ X2 @ Vt.T @ np.diag(1./S)\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(A_tilde)\n",
        "\n",
        "        # Reconstruct the DMD modes (Phi)\n",
        "        dmd_modes = X2 @ Vt.T @ np.diag(1./S) @ eigenvectors\n",
        "\n",
        "        # --- 4. Calculate Frequencies ---\n",
        "        frequencies = np.imag(np.log(eigenvalues) / dt) / (2 * np.pi)\n",
        "\n",
        "        # --- 5. Calculate Modal Amplitudes ---\n",
        "        # The amplitudes (b) are calculated by projecting the initial state (x0) onto the DMD modes.\n",
        "        x0 = X[:, 0]\n",
        "        b = np.linalg.pinv(dmd_modes) @ x0\n",
        "\n",
        "        # --- 6. Find the Dominant Mode and its Properties ---\n",
        "        # We look for the mode with the highest amplitude, ignoring near-zero frequencies.\n",
        "        valid_indices = np.where(np.abs(frequencies) > 1)[0]\n",
        "        if len(valid_indices) == 0:\n",
        "            return None, None\n",
        "\n",
        "        # Find the index of the mode with the maximum amplitude 'b'\n",
        "        dominant_mode_idx = valid_indices[np.argmax(np.abs(b[valid_indices]))]\n",
        "\n",
        "        dominant_frequency = frequencies[dominant_mode_idx]\n",
        "        modal_amplitude = np.abs(b[dominant_mode_idx])\n",
        "\n",
        "        return dominant_frequency, modal_amplitude\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process {os.path.basename(file_path)}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# ==============================================================================\n",
        "# Main script to run the analysis on all files\n",
        "# ==============================================================================\n",
        "\n",
        "# Find all data files in the directory\n",
        "all_files = sorted(glob.glob('Velocity_*.txt'))\n",
        "results = []\n",
        "\n",
        "if not all_files:\n",
        "    print(\"‚ùå No data files found! Make sure your '.txt' files are present.\")\n",
        "else:\n",
        "    print(f\"Found {len(all_files)} files. Starting analysis...\")\n",
        "    # Loop through each file and store the results\n",
        "    for path in all_files:\n",
        "        freq, amp = analyze_dmd_results(path)\n",
        "        if freq is not None and amp is not None:\n",
        "            results.append({\n",
        "                \"File Name\": os.path.basename(path),\n",
        "                \"Dominant Frequency (Hz)\": freq,\n",
        "                \"Modal Amplitude\": amp\n",
        "            })\n",
        "\n",
        "# --- Print Final Summary Table ---\n",
        "print(\"\\n\\n--- üìä FINAL RESULTS: Frequency and Amplitude ---\")\n",
        "\n",
        "if results:\n",
        "    # Convert results to a pandas DataFrame for nice printing\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(results_df.to_string(index=False, float_format=\"%.2f\"))\n",
        "else:\n",
        "    print(\"No results to display. Please check for errors during analysis.\")"
      ],
      "metadata": {
        "id": "NhQsZaEHXfQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import svd\n",
        "import os\n",
        "\n",
        "# --- 1. Load the Data ---\n",
        "file_path = 'Velocity_1C50_16ms.txt'\n",
        "print(f\"Analyzing file: {os.path.basename(file_path)}\")\n",
        "\n",
        "data = pd.read_csv(file_path, sep='\\s+', header=None, names=['time', 'velocity'])\n",
        "signal = data['velocity'].values\n",
        "time = data['time'].values\n",
        "\n",
        "# --- 2. Create the Snapshot Matrix ---\n",
        "window_size = 1000\n",
        "n_snapshots = len(signal) - window_size + 1\n",
        "X = np.array([signal[i:i + window_size] for i in range(n_snapshots)]).T\n",
        "\n",
        "# --- 3. Perform POD (SVD) ---\n",
        "# U: POD modes (spatial shapes)\n",
        "# S: Singular values (energy of each mode)\n",
        "# Vt: Time evolution of each mode\n",
        "U, S, Vt = svd(X, full_matrices=False)\n",
        "print(\"POD calculation complete.\")\n",
        "\n",
        "# --- 4. Calculate the Time Coefficients ---\n",
        "# The actual time coefficients are the rows of Vt scaled by their corresponding singular value.\n",
        "# coeffs = np.diag(S) @ Vt\n",
        "# However, for visualization, plotting the rows of Vt is sufficient and standard.\n",
        "time_coeffs = Vt\n",
        "\n",
        "# --- 5. Create the Corresponding Time Vector ---\n",
        "# The time coefficients correspond to each snapshot, not each original data point.\n",
        "time_vector = time[:n_snapshots]\n",
        "\n",
        "# --- 6. Plot the Results ---\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Plot the time coefficients for the first 4 modes\n",
        "for i in range(4):\n",
        "    plt.plot(time_vector, time_coeffs[i, :], label=f'Mode {i+1} Amplitude')\n",
        "\n",
        "plt.title('Modal Amplitude (Time Coefficients) vs. Time', fontsize=16)\n",
        "plt.xlabel('Time (s)', fontsize=12)\n",
        "plt.ylabel('Modal Amplitude (Arbitrary Units)', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xlim(0, 15) # Zoom in on the first 15 seconds to see the oscillations clearly\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z_xXIJKPXv0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import svd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# --- 1. Find all the velocity data files ---\n",
        "all_files = sorted(glob.glob('Velocity_*.txt'))\n",
        "\n",
        "if not all_files:\n",
        "    print(\"‚ùå No data files found! Make sure your '.txt' files are in the correct directory.\")\n",
        "else:\n",
        "    print(f\"Found {len(all_files)} files. Generating plots for each...\")\n",
        "\n",
        "    # --- 2. Loop through each file and create a plot ---\n",
        "    for file_path in all_files:\n",
        "        print(f\"\\n--- Processing: {os.path.basename(file_path)} ---\")\n",
        "\n",
        "        # --- Load the data for the current file ---\n",
        "        data = pd.read_csv(file_path, sep='\\s+', header=None, names=['time', 'velocity'])\n",
        "        signal = data['velocity'].values\n",
        "        time = data['time'].values\n",
        "\n",
        "        # --- Create the Snapshot Matrix ---\n",
        "        window_size = 1000\n",
        "        n_snapshots = len(signal) - window_size + 1\n",
        "        X = np.array([signal[i:i + window_size] for i in range(n_snapshots)]).T\n",
        "\n",
        "        # --- Perform POD (SVD) ---\n",
        "        U, S, Vt = svd(X, full_matrices=False)\n",
        "\n",
        "        # Vt contains the time evolution of each mode\n",
        "        time_coeffs = Vt\n",
        "\n",
        "        # --- Create the Corresponding Time Vector ---\n",
        "        time_vector = time[:n_snapshots]\n",
        "\n",
        "        # --- Plot the Results for the current file ---\n",
        "        plt.figure(figsize=(15, 8))\n",
        "\n",
        "        # Plot the time coefficients for the first 4 modes\n",
        "        for i in range(4):\n",
        "            plt.plot(time_vector, time_coeffs[i, :], label=f'Mode {i+1} Amplitude')\n",
        "\n",
        "        # Use the file name in the title\n",
        "        plt.title(f'Modal Amplitude vs. Time for {os.path.basename(file_path)}', fontsize=16)\n",
        "        plt.xlabel('Time (s)', fontsize=12)\n",
        "        plt.ylabel('Modal Amplitude (Arbitrary Units)', fontsize=12)\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.xlim(0, 15)  # Zoom in on the first 15 seconds to see details\n",
        "        plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ All files have been processed and plotted.\")"
      ],
      "metadata": {
        "id": "QKi2Fm0misih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import svd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# --- 1. Set the Plot Style to \"Dark Mode\" ---\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "# --- 2. Define a function to create the \"glow\" effect ---\n",
        "def plot_glow_effect(ax, x, y, color, label, n_glow_lines=10):\n",
        "    \"\"\"\n",
        "    Plots a line with a soft glow effect on the given axes.\n",
        "    \"\"\"\n",
        "    # Draw several faint, thick lines underneath the main line to create the glow\n",
        "    for i in range(n_glow_lines):\n",
        "        ax.plot(x, y, linewidth=2 + i * 1.5, color=color, alpha=0.05)\n",
        "    # Draw the main, bright line on top\n",
        "    ax.plot(x, y, linewidth=1.5, color=color, label=label)\n",
        "\n",
        "\n",
        "# --- 3. Find all the velocity data files ---\n",
        "all_files = sorted(glob.glob('Velocity_*.txt'))\n",
        "\n",
        "if not all_files:\n",
        "    print(\"‚ùå No data files found! Make sure your '.txt' files are in the correct directory.\")\n",
        "else:\n",
        "    print(f\"Found {len(all_files)} files. Generating stylized plots for each...\")\n",
        "\n",
        "    # Define a list of neon colors for the different modes\n",
        "    neon_colors = ['#08F7FE', '#FE53BB', '#F5D300', '#00ff41']\n",
        "\n",
        "    # --- 4. Loop through each file and create a plot ---\n",
        "    for file_path in all_files:\n",
        "        print(f\"\\n--- Processing: {os.path.basename(file_path)} ---\")\n",
        "\n",
        "        # Load the data for the current file\n",
        "        data = pd.read_csv(file_path, sep='\\s+', header=None, names=['time', 'velocity'])\n",
        "        signal = data['velocity'].values\n",
        "        time = data['time'].values\n",
        "\n",
        "        # Perform POD (SVD)\n",
        "        window_size = 1000\n",
        "        n_snapshots = len(signal) - window_size + 1\n",
        "        X = np.array([signal[i:i + window_size] for i in range(n_snapshots)]).T\n",
        "        U, S, Vt = svd(X, full_matrices=False)\n",
        "        time_coeffs = Vt\n",
        "        time_vector = time[:n_snapshots]\n",
        "\n",
        "        # --- 5. Create the Stylized Plot ---\n",
        "        fig, ax = plt.subplots(figsize=(15, 8))\n",
        "\n",
        "        # Plot the time coefficients for the first 4 modes with the glow effect\n",
        "        for i in range(4):\n",
        "            plot_glow_effect(ax, time_vector, time_coeffs[i, :], color=neon_colors[i], label=f'Mode {i+1}')\n",
        "\n",
        "        # --- 6. Customize the plot appearance ---\n",
        "        ax.set_title(f'Modal Amplitude vs. Time for {os.path.basename(file_path)}', fontsize=18, color='white')\n",
        "        ax.set_xlabel('Time (s)', fontsize=14, color='white')\n",
        "        ax.set_ylabel('Modal Amplitude', fontsize=14, color='white')\n",
        "\n",
        "        # Customize ticks and legend\n",
        "        ax.tick_params(axis='x', colors='white')\n",
        "        ax.tick_params(axis='y', colors='white')\n",
        "        legend = ax.legend()\n",
        "        for text in legend.get_texts():\n",
        "            text.set_color('white')\n",
        "\n",
        "        # Remove the grid and make axis lines white\n",
        "        ax.grid(False)\n",
        "        for spine in ax.spines.values():\n",
        "            spine.set_edgecolor('white')\n",
        "\n",
        "        ax.set_xlim(0, 15) # Zoom in on the first 15 seconds\n",
        "        plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ All files have been processed and plotted.\")"
      ],
      "metadata": {
        "id": "PrjsNuUKjIdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.linalg import svd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# --- 1. Find all the velocity data files ---\n",
        "all_files = sorted(glob.glob('Velocity_*.txt'))\n",
        "\n",
        "if not all_files:\n",
        "    print(\"‚ùå No data files found! Make sure your '.txt' files are in the correct directory.\")\n",
        "else:\n",
        "    print(f\"Found {len(all_files)} files. Generating pcolormesh plots for each...\")\n",
        "\n",
        "    # --- 2. Loop through each file and create a plot ---\n",
        "    for file_path in all_files:\n",
        "        print(f\"\\n--- Processing: {os.path.basename(file_path)} ---\")\n",
        "\n",
        "        # --- Load the data ---\n",
        "        data = pd.read_csv(file_path, sep='\\s+', header=None, names=['time', 'velocity'])\n",
        "        signal = data['velocity'].values\n",
        "        time = data['time'].values\n",
        "\n",
        "        # --- Create the Snapshot Matrix ---\n",
        "        window_size = 500 # Using a slightly smaller window for better visualization\n",
        "        n_snapshots = len(signal) - window_size + 1\n",
        "        X = np.array([signal[i:i + window_size] for i in range(n_snapshots)]).T\n",
        "\n",
        "        # --- Perform POD (SVD) ---\n",
        "        U, S, Vt = svd(X, full_matrices=False)\n",
        "\n",
        "        # --- Reconstruct the data using the first 6 dominant modes ---\n",
        "        # This highlights the main coherent structures and filters noise.\n",
        "        n_modes_to_use = 6\n",
        "        X_reconstructed = U[:, :n_modes_to_use] @ np.diag(S[:n_modes_to_use]) @ Vt[:n_modes_to_use, :]\n",
        "\n",
        "        # Subtract the mean to focus on fluctuations (vortices)\n",
        "        X_reconstructed = X_reconstructed - np.mean(X_reconstructed)\n",
        "\n",
        "        # --- Create Coordinate Vectors for the Plot ---\n",
        "        time_vector = time[:n_snapshots]\n",
        "        space_vector = np.arange(window_size)\n",
        "\n",
        "        # --- Create the pcolormesh Plot ---\n",
        "        plt.figure(figsize=(16, 8))\n",
        "\n",
        "        # Use a diverging colormap like 'seismic' or 'RdBu' which is great for flow fields\n",
        "        # It shows positive fluctuations in one color and negative in another.\n",
        "        plt.pcolormesh(time_vector, space_vector, X_reconstructed, cmap='seismic', shading='gouraud')\n",
        "\n",
        "        # --- Customize the Plot ---\n",
        "        plt.colorbar(label='Velocity Fluctuation (m/s)')\n",
        "        plt.title(f'Reconstructed Flow Dynamics for {os.path.basename(file_path)}', fontsize=16)\n",
        "        plt.xlabel('Time (s)', fontsize=12)\n",
        "        plt.ylabel('Position in Snapshot Window', fontsize=12)\n",
        "        plt.xlim(0, 20) # Zoom in on the first 20 seconds to see the structure\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ All files have been processed and plotted.\")"
      ],
      "metadata": {
        "id": "PS-RySi2kEyb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}